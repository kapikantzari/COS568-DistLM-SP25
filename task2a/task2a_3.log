03/25/2025 13:03:55 - WARNING - __main__ -   Process rank: 3, device: cpu, distributed training: True, 16-bits training: False
03/25/2025 13:04:04 - INFO - pytorch_transformers.modeling_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /users/yc6206/.cache/torch/pytorch_transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.9da767be51e1327499df13488672789394e2ca38b877837e52618a67d7002391
03/25/2025 13:04:04 - INFO - pytorch_transformers.modeling_utils -   Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": "rte",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "pad_token_id": 0,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28996
}

03/25/2025 13:04:04 - INFO - pytorch_transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /users/yc6206/.cache/torch/pytorch_transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1
03/25/2025 13:04:05 - INFO - pytorch_transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at /users/yc6206/.cache/torch/pytorch_transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2
03/25/2025 13:04:13 - INFO - pytorch_transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
03/25/2025 13:04:13 - INFO - pytorch_transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
03/25/2025 13:04:13 - INFO - __main__ -   Training/evaluation parameters Namespace(data_dir='/proj/cos568proj2-PG0/glue_data/RTE', model_type='bert', model_name_or_path='bert-base-cased', task_name='rte', output_dir='/tmp/RTE/', config_name='', tokenizer_name='', cache_dir='', max_seq_length=128, do_train=True, do_eval=True, do_lower_case=False, per_device_train_batch_size=16, per_device_eval_batch_size=8, gradient_accumulation_steps=1, learning_rate=2e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=1.0, max_steps=-1, warmup_steps=0, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=42, fp16=False, fp16_opt_level='O1', local_rank=3, master_ip='10.10.1.2', master_port='12345', world_size=4, device=device(type='cpu'), n_gpu=0, output_mode='classification')
03/25/2025 13:04:13 - INFO - __main__ -   Loading features from cached file /proj/cos568proj2-PG0/glue_data/RTE/cached_train_bert-base-cased_128_rte
03/25/2025 13:04:15 - INFO - __main__ -   ***** Running training *****
03/25/2025 13:04:15 - INFO - __main__ -     Num examples = 2490
03/25/2025 13:04:15 - INFO - __main__ -     Num Epochs = 1
03/25/2025 13:04:15 - INFO - __main__ -     Instantaneous batch size per device = 16
03/25/2025 13:04:15 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 64
03/25/2025 13:04:15 - INFO - __main__ -     Gradient Accumulation steps = 1
03/25/2025 13:04:15 - INFO - __main__ -     Total optimization steps = 39
03/25/2025 13:04:25 - INFO - __main__ -   Time: 9.05154704600045
03/25/2025 13:04:32 - INFO - __main__ -   Time: 7.789304052999796
03/25/2025 13:04:40 - INFO - __main__ -   Time: 7.585239473999536
03/25/2025 13:04:47 - INFO - __main__ -   Time: 7.252450868999404
03/25/2025 13:04:53 - INFO - __main__ -   Time: 6.2494877609997275
03/25/2025 13:05:00 - INFO - __main__ -   Time: 6.511286060000202
03/25/2025 13:05:06 - INFO - __main__ -   Time: 6.167225142999996
03/25/2025 13:05:13 - INFO - __main__ -   Time: 7.002352796000196
03/25/2025 13:05:19 - INFO - __main__ -   Time: 6.301167448999877
03/25/2025 13:05:26 - INFO - __main__ -   Time: 6.14222914200036
03/25/2025 13:05:32 - INFO - __main__ -   Time: 6.464852779000466
03/25/2025 13:05:38 - INFO - __main__ -   Time: 6.163696763000189
03/25/2025 13:05:44 - INFO - __main__ -   Time: 6.068461490999653
03/25/2025 13:05:51 - INFO - __main__ -   Time: 6.340214433000256
03/25/2025 13:05:57 - INFO - __main__ -   Time: 6.14929737500006
03/25/2025 13:06:03 - INFO - __main__ -   Time: 5.916244914000345
03/25/2025 13:06:09 - INFO - __main__ -   Time: 6.169803597999817
03/25/2025 13:06:15 - INFO - __main__ -   Time: 6.166686730999572
03/25/2025 13:06:21 - INFO - __main__ -   Time: 6.240864133999821
03/25/2025 13:06:28 - INFO - __main__ -   Time: 6.39359561800029
03/25/2025 13:06:34 - INFO - __main__ -   Time: 6.1064891109999735
03/25/2025 13:06:40 - INFO - __main__ -   Time: 6.021597706999273
03/25/2025 13:06:46 - INFO - __main__ -   Time: 5.988478096999643
03/25/2025 13:06:52 - INFO - __main__ -   Time: 6.2366295869996975
03/25/2025 13:06:58 - INFO - __main__ -   Time: 6.167188768000415
03/25/2025 13:07:04 - INFO - __main__ -   Time: 5.9980081040002915
03/25/2025 13:07:11 - INFO - __main__ -   Time: 6.441268601000047
03/25/2025 13:07:17 - INFO - __main__ -   Time: 6.121722148000117
03/25/2025 13:07:23 - INFO - __main__ -   Time: 6.196422605000407
03/25/2025 13:07:29 - INFO - __main__ -   Time: 5.892597693000425
03/25/2025 13:07:35 - INFO - __main__ -   Time: 6.040658353999788
03/25/2025 13:07:41 - INFO - __main__ -   Time: 6.315093675999378
03/25/2025 13:07:47 - INFO - __main__ -   Time: 6.008207120999941
03/25/2025 13:07:54 - INFO - __main__ -   Time: 6.684913578000305
03/25/2025 13:08:00 - INFO - __main__ -   Time: 6.264114896000137
03/25/2025 13:08:07 - INFO - __main__ -   Time: 6.7860589690008055
03/25/2025 13:08:13 - INFO - __main__ -   Time: 6.29761114699977
03/25/2025 13:08:20 - INFO - __main__ -   Time: 6.566222019000634
03/25/2025 13:08:26 - INFO - __main__ -   Time: 6.0413360069997
03/25/2025 13:08:26 - INFO - __main__ -   Loading features from cached file /proj/cos568proj2-PG0/glue_data/RTE/cached_dev_bert-base-cased_128_rte
03/25/2025 13:08:26 - INFO - __main__ -   ***** Running evaluation  *****
03/25/2025 13:08:26 - INFO - __main__ -     Num examples = 277
03/25/2025 13:08:26 - INFO - __main__ -     Batch size = 8
03/25/2025 13:08:26 - INFO - __main__ -   loss: 0.6792740225791931
03/25/2025 13:08:27 - INFO - __main__ -   loss: 0.6594865322113037
03/25/2025 13:08:27 - INFO - __main__ -   loss: 0.6278610229492188
03/25/2025 13:08:27 - INFO - __main__ -   loss: 0.7215309143066406
03/25/2025 13:08:28 - INFO - __main__ -   loss: 0.7119662761688232
03/25/2025 13:08:28 - INFO - __main__ -   loss: 0.6950995922088623
03/25/2025 13:08:28 - INFO - __main__ -   loss: 0.6862903833389282
03/25/2025 13:08:29 - INFO - __main__ -   loss: 0.6751019954681396
03/25/2025 13:08:29 - INFO - __main__ -   loss: 0.6292955875396729
03/25/2025 13:08:29 - INFO - __main__ -   loss: 0.7162505984306335
03/25/2025 13:08:30 - INFO - __main__ -   loss: 0.6872202157974243
03/25/2025 13:08:30 - INFO - __main__ -   loss: 0.7055074572563171
03/25/2025 13:08:31 - INFO - __main__ -   loss: 0.65382319688797
03/25/2025 13:08:31 - INFO - __main__ -   loss: 0.609268844127655
03/25/2025 13:08:31 - INFO - __main__ -   loss: 0.6504175066947937
03/25/2025 13:08:32 - INFO - __main__ -   loss: 0.7686682939529419
03/25/2025 13:08:32 - INFO - __main__ -   loss: 0.6355128288269043
03/25/2025 13:08:32 - INFO - __main__ -   loss: 0.6749215722084045
03/25/2025 13:08:33 - INFO - __main__ -   loss: 0.6691346168518066
03/25/2025 13:08:33 - INFO - __main__ -   loss: 0.6421698331832886
03/25/2025 13:08:33 - INFO - __main__ -   loss: 0.7326953411102295
03/25/2025 13:08:34 - INFO - __main__ -   loss: 0.6275438070297241
03/25/2025 13:08:34 - INFO - __main__ -   loss: 0.6745201349258423
03/25/2025 13:08:34 - INFO - __main__ -   loss: 0.6563472151756287
03/25/2025 13:08:35 - INFO - __main__ -   loss: 0.7076627016067505
03/25/2025 13:08:35 - INFO - __main__ -   loss: 0.6605845093727112
03/25/2025 13:08:35 - INFO - __main__ -   loss: 0.6894660592079163
03/25/2025 13:08:36 - INFO - __main__ -   loss: 0.7039376497268677
03/25/2025 13:08:36 - INFO - __main__ -   loss: 0.6192374229431152
03/25/2025 13:08:36 - INFO - __main__ -   loss: 0.7024819254875183
03/25/2025 13:08:37 - INFO - __main__ -   loss: 0.6923795938491821
03/25/2025 13:08:37 - INFO - __main__ -   loss: 0.6996857523918152
03/25/2025 13:08:37 - INFO - __main__ -   loss: 0.6295852065086365
03/25/2025 13:08:38 - INFO - __main__ -   loss: 0.6898556351661682
03/25/2025 13:08:38 - INFO - __main__ -   loss: 0.6182768940925598
03/25/2025 13:08:38 - INFO - __main__ -   ***** Eval results  *****
03/25/2025 13:08:38 - INFO - __main__ -     acc = 0.5848375451263538
03/25/2025 13:08:38 - INFO - __main__ -   Average time (excluding 1st iteration): 6.348659967657903
03/25/2025 13:08:38 - INFO - __main__ -   All losses: [0.7816948890686035, 0.6143265962600708, 0.6437394618988037, 0.8161934614181519, 0.7411607503890991, 0.6466996669769287, 0.7845600843429565, 0.7537937164306641, 0.8423177599906921, 0.7069649696350098, 0.7188005447387695, 0.7441220879554749, 0.7273543477058411, 0.6782702207565308, 0.7138475179672241, 0.6852669715881348, 0.7051742672920227, 0.6337584853172302, 0.6820027828216553, 0.6660043597221375, 0.6386429667472839, 0.6844572424888611, 0.7148404121398926, 0.6874883770942688, 0.7233012318611145, 0.6762521862983704, 0.7094919681549072, 0.654076099395752, 0.6662467122077942, 0.614262044429779, 0.692227303981781, 0.7011114358901978, 0.6652346849441528, 0.6966446042060852, 0.6910601258277893, 0.7210373878479004, 0.6465932130813599, 0.6939706206321716, 0.6482515931129456]
03/25/2025 13:08:38 - INFO - __main__ -    global_step = 39, average loss = 0.697724183400472
03/25/2025 13:08:40 - INFO - __main__ -   Loading features from cached file /proj/cos568proj2-PG0/glue_data/RTE/cached_dev_bert-base-cased_128_rte
03/25/2025 13:08:40 - INFO - __main__ -   ***** Running evaluation  *****
03/25/2025 13:08:40 - INFO - __main__ -     Num examples = 277
03/25/2025 13:08:40 - INFO - __main__ -     Batch size = 8
03/25/2025 13:08:40 - INFO - __main__ -   loss: 0.6792740225791931
03/25/2025 13:08:41 - INFO - __main__ -   loss: 0.6594865322113037
03/25/2025 13:08:41 - INFO - __main__ -   loss: 0.6278610229492188
03/25/2025 13:08:41 - INFO - __main__ -   loss: 0.7215309143066406
03/25/2025 13:08:42 - INFO - __main__ -   loss: 0.7119662761688232
03/25/2025 13:08:42 - INFO - __main__ -   loss: 0.6950995922088623
03/25/2025 13:08:42 - INFO - __main__ -   loss: 0.6862903833389282
03/25/2025 13:08:43 - INFO - __main__ -   loss: 0.6751019954681396
03/25/2025 13:08:43 - INFO - __main__ -   loss: 0.6292955875396729
03/25/2025 13:08:43 - INFO - __main__ -   loss: 0.7162505984306335
03/25/2025 13:08:44 - INFO - __main__ -   loss: 0.6872202157974243
03/25/2025 13:08:44 - INFO - __main__ -   loss: 0.7055074572563171
03/25/2025 13:08:44 - INFO - __main__ -   loss: 0.65382319688797
03/25/2025 13:08:45 - INFO - __main__ -   loss: 0.609268844127655
03/25/2025 13:08:45 - INFO - __main__ -   loss: 0.6504175066947937
03/25/2025 13:08:45 - INFO - __main__ -   loss: 0.7686682939529419
03/25/2025 13:08:46 - INFO - __main__ -   loss: 0.6355128288269043
03/25/2025 13:08:46 - INFO - __main__ -   loss: 0.6749215722084045
03/25/2025 13:08:46 - INFO - __main__ -   loss: 0.6691346168518066
03/25/2025 13:08:47 - INFO - __main__ -   loss: 0.6421698331832886
03/25/2025 13:08:47 - INFO - __main__ -   loss: 0.7326953411102295
03/25/2025 13:08:47 - INFO - __main__ -   loss: 0.6275438070297241
03/25/2025 13:08:48 - INFO - __main__ -   loss: 0.6745201349258423
03/25/2025 13:08:48 - INFO - __main__ -   loss: 0.6563472151756287
03/25/2025 13:08:49 - INFO - __main__ -   loss: 0.7076627016067505
03/25/2025 13:08:49 - INFO - __main__ -   loss: 0.6605845093727112
03/25/2025 13:08:49 - INFO - __main__ -   loss: 0.6894660592079163
03/25/2025 13:08:50 - INFO - __main__ -   loss: 0.7039376497268677
03/25/2025 13:08:50 - INFO - __main__ -   loss: 0.6192374229431152
03/25/2025 13:08:50 - INFO - __main__ -   loss: 0.7024819254875183
03/25/2025 13:08:51 - INFO - __main__ -   loss: 0.6923795938491821
03/25/2025 13:08:51 - INFO - __main__ -   loss: 0.6996857523918152
03/25/2025 13:08:51 - INFO - __main__ -   loss: 0.6295852065086365
03/25/2025 13:08:52 - INFO - __main__ -   loss: 0.6898556351661682
03/25/2025 13:08:52 - INFO - __main__ -   loss: 0.6182768940925598
03/25/2025 13:08:52 - INFO - __main__ -   ***** Eval results  *****
03/25/2025 13:08:52 - INFO - __main__ -     acc = 0.5848375451263538
