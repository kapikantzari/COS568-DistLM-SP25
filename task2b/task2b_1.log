03/25/2025 13:46:14 - WARNING - __main__ -   Process rank: 1, device: cpu, distributed training: True, 16-bits training: False
03/25/2025 13:46:23 - INFO - pytorch_transformers.modeling_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /users/yc6206/.cache/torch/pytorch_transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.9da767be51e1327499df13488672789394e2ca38b877837e52618a67d7002391
03/25/2025 13:46:23 - INFO - pytorch_transformers.modeling_utils -   Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": "rte",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "pad_token_id": 0,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28996
}

03/25/2025 13:46:24 - INFO - pytorch_transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /users/yc6206/.cache/torch/pytorch_transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1
03/25/2025 13:46:24 - INFO - pytorch_transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at /users/yc6206/.cache/torch/pytorch_transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2
03/25/2025 13:46:33 - INFO - pytorch_transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
03/25/2025 13:46:33 - INFO - pytorch_transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
03/25/2025 13:46:33 - INFO - __main__ -   Training/evaluation parameters Namespace(data_dir='/proj/cos568proj2-PG0/glue_data/RTE', model_type='bert', model_name_or_path='bert-base-cased', task_name='rte', output_dir='/tmp/RTE/', config_name='', tokenizer_name='', cache_dir='', max_seq_length=128, do_train=True, do_eval=True, do_lower_case=False, per_device_train_batch_size=16, per_device_eval_batch_size=8, gradient_accumulation_steps=1, learning_rate=2e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=1.0, max_steps=-1, warmup_steps=0, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=42, fp16=False, fp16_opt_level='O1', local_rank=1, master_ip='10.10.1.2', master_port='12345', world_size=4, device=device(type='cpu'), n_gpu=0, output_mode='classification')
03/25/2025 13:46:33 - INFO - __main__ -   Loading features from cached file /proj/cos568proj2-PG0/glue_data/RTE/cached_train_bert-base-cased_128_rte
03/25/2025 13:46:35 - INFO - __main__ -   ***** Running training *****
03/25/2025 13:46:35 - INFO - __main__ -     Num examples = 2490
03/25/2025 13:46:35 - INFO - __main__ -     Num Epochs = 1
03/25/2025 13:46:35 - INFO - __main__ -     Instantaneous batch size per device = 16
03/25/2025 13:46:35 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 64
03/25/2025 13:46:35 - INFO - __main__ -     Gradient Accumulation steps = 1
03/25/2025 13:46:35 - INFO - __main__ -     Total optimization steps = 39
03/25/2025 13:46:40 - INFO - __main__ -   Time: 5.641200308000407
03/25/2025 13:46:45 - INFO - __main__ -   Time: 5.091152957000304
03/25/2025 13:46:50 - INFO - __main__ -   Time: 4.058674036999946
03/25/2025 13:46:54 - INFO - __main__ -   Time: 4.108994189000441
03/25/2025 13:46:57 - INFO - __main__ -   Time: 3.3760403510004835
03/25/2025 13:47:01 - INFO - __main__ -   Time: 3.6871074299997417
03/25/2025 13:47:04 - INFO - __main__ -   Time: 3.6175584030006576
03/25/2025 13:47:08 - INFO - __main__ -   Time: 3.6586119719995622
03/25/2025 13:47:11 - INFO - __main__ -   Time: 3.2408538439995027
03/25/2025 13:47:15 - INFO - __main__ -   Time: 3.3738688720004575
03/25/2025 13:47:18 - INFO - __main__ -   Time: 3.410037055999055
03/25/2025 13:47:22 - INFO - __main__ -   Time: 3.5332313979997707
03/25/2025 13:47:25 - INFO - __main__ -   Time: 3.4764132529999188
03/25/2025 13:47:28 - INFO - __main__ -   Time: 3.4211633980012266
03/25/2025 13:47:32 - INFO - __main__ -   Time: 3.2189465519986697
03/25/2025 13:47:35 - INFO - __main__ -   Time: 3.301654499000506
03/25/2025 13:47:38 - INFO - __main__ -   Time: 3.1238395899999887
03/25/2025 13:47:41 - INFO - __main__ -   Time: 3.2634911320001265
03/25/2025 13:47:45 - INFO - __main__ -   Time: 3.234382392000043
03/25/2025 13:47:48 - INFO - __main__ -   Time: 3.2952872779987956
03/25/2025 13:47:51 - INFO - __main__ -   Time: 3.2557361099989066
03/25/2025 13:47:54 - INFO - __main__ -   Time: 3.2356690279993927
03/25/2025 13:47:58 - INFO - __main__ -   Time: 3.2610520390007878
03/25/2025 13:48:01 - INFO - __main__ -   Time: 3.2764982610005973
03/25/2025 13:48:04 - INFO - __main__ -   Time: 3.3242708039997524
03/25/2025 13:48:08 - INFO - __main__ -   Time: 3.4900110229991697
03/25/2025 13:48:11 - INFO - __main__ -   Time: 3.6317051040005026
03/25/2025 13:48:15 - INFO - __main__ -   Time: 3.446893672000442
03/25/2025 13:48:18 - INFO - __main__ -   Time: 3.3712440700001025
03/25/2025 13:48:21 - INFO - __main__ -   Time: 3.156903360000797
03/25/2025 13:48:25 - INFO - __main__ -   Time: 3.1827588890009793
03/25/2025 13:48:28 - INFO - __main__ -   Time: 3.1854484480008978
03/25/2025 13:48:31 - INFO - __main__ -   Time: 3.1860921640000015
03/25/2025 13:48:34 - INFO - __main__ -   Time: 3.1974552560004668
03/25/2025 13:48:37 - INFO - __main__ -   Time: 3.1750634379986877
03/25/2025 13:48:41 - INFO - __main__ -   Time: 3.2575155710001127
03/25/2025 13:48:44 - INFO - __main__ -   Time: 3.372537110999474
03/25/2025 13:48:47 - INFO - __main__ -   Time: 3.326324420999299
03/25/2025 13:48:50 - INFO - __main__ -   Time: 3.1281593889998476
03/25/2025 13:48:50 - INFO - __main__ -   Loading features from cached file /proj/cos568proj2-PG0/glue_data/RTE/cached_dev_bert-base-cased_128_rte
03/25/2025 13:48:50 - INFO - __main__ -   ***** Running evaluation  *****
03/25/2025 13:48:50 - INFO - __main__ -     Num examples = 277
03/25/2025 13:48:50 - INFO - __main__ -     Batch size = 8
03/25/2025 13:48:51 - INFO - __main__ -   loss: 0.6792739629745483
03/25/2025 13:48:51 - INFO - __main__ -   loss: 0.6594865918159485
03/25/2025 13:48:52 - INFO - __main__ -   loss: 0.627860963344574
03/25/2025 13:48:52 - INFO - __main__ -   loss: 0.7215308547019958
03/25/2025 13:48:52 - INFO - __main__ -   loss: 0.7119660973548889
03/25/2025 13:48:53 - INFO - __main__ -   loss: 0.6950995326042175
03/25/2025 13:48:53 - INFO - __main__ -   loss: 0.6862902641296387
03/25/2025 13:48:53 - INFO - __main__ -   loss: 0.6751022338867188
03/25/2025 13:48:54 - INFO - __main__ -   loss: 0.6292954683303833
03/25/2025 13:48:54 - INFO - __main__ -   loss: 0.7162505388259888
03/25/2025 13:48:55 - INFO - __main__ -   loss: 0.6872202754020691
03/25/2025 13:48:55 - INFO - __main__ -   loss: 0.7055076360702515
03/25/2025 13:48:55 - INFO - __main__ -   loss: 0.6538232564926147
03/25/2025 13:48:56 - INFO - __main__ -   loss: 0.6092687845230103
03/25/2025 13:48:56 - INFO - __main__ -   loss: 0.6504174470901489
03/25/2025 13:48:56 - INFO - __main__ -   loss: 0.7686682939529419
03/25/2025 13:48:57 - INFO - __main__ -   loss: 0.6355127096176147
03/25/2025 13:48:57 - INFO - __main__ -   loss: 0.6749213933944702
03/25/2025 13:48:57 - INFO - __main__ -   loss: 0.6691347360610962
03/25/2025 13:48:58 - INFO - __main__ -   loss: 0.6421696543693542
03/25/2025 13:48:58 - INFO - __main__ -   loss: 0.7326954007148743
03/25/2025 13:48:58 - INFO - __main__ -   loss: 0.6275437474250793
03/25/2025 13:48:59 - INFO - __main__ -   loss: 0.6745201945304871
03/25/2025 13:48:59 - INFO - __main__ -   loss: 0.6563470363616943
03/25/2025 13:48:59 - INFO - __main__ -   loss: 0.7076627016067505
03/25/2025 13:49:00 - INFO - __main__ -   loss: 0.6605845093727112
03/25/2025 13:49:00 - INFO - __main__ -   loss: 0.689466118812561
03/25/2025 13:49:00 - INFO - __main__ -   loss: 0.7039375901222229
03/25/2025 13:49:01 - INFO - __main__ -   loss: 0.6192373037338257
03/25/2025 13:49:01 - INFO - __main__ -   loss: 0.7024820446968079
03/25/2025 13:49:01 - INFO - __main__ -   loss: 0.6923796534538269
03/25/2025 13:49:02 - INFO - __main__ -   loss: 0.6996857523918152
03/25/2025 13:49:02 - INFO - __main__ -   loss: 0.6295850872993469
03/25/2025 13:49:03 - INFO - __main__ -   loss: 0.6898555755615234
03/25/2025 13:49:03 - INFO - __main__ -   loss: 0.6182767748832703
03/25/2025 13:49:03 - INFO - __main__ -   ***** Eval results  *****
03/25/2025 13:49:03 - INFO - __main__ -     acc = 0.5848375451263538
03/25/2025 13:49:03 - INFO - __main__ -   Average time (excluding 1st iteration): 3.419806493710511
03/25/2025 13:49:03 - INFO - __main__ -   All losses: [0.7578274011611938, 0.8156551122665405, 0.8053343296051025, 0.6981641054153442, 0.754859209060669, 0.7134767770767212, 0.6706017255783081, 0.7023771405220032, 0.700482964515686, 0.7762758731842041, 0.6426709890365601, 0.6702830791473389, 0.6886624097824097, 0.6659002900123596, 0.7513875961303711, 0.7162238955497742, 0.7070179581642151, 0.6726266741752625, 0.7133543491363525, 0.6855461597442627, 0.6801287531852722, 0.6922923922538757, 0.7572696805000305, 0.6359397172927856, 0.6955274343490601, 0.7020452618598938, 0.6732689738273621, 0.6796047687530518, 0.6426557302474976, 0.6674259305000305, 0.6453572511672974, 0.647204577922821, 0.7489371299743652, 0.6792039275169373, 0.7209844589233398, 0.7291515469551086, 0.6776719093322754, 0.6735637784004211, 0.6358706951141357]
03/25/2025 13:49:03 - INFO - __main__ -    global_step = 39, average loss = 0.6998162040343652
03/25/2025 13:49:03 - INFO - __main__ -   Loading features from cached file /proj/cos568proj2-PG0/glue_data/RTE/cached_dev_bert-base-cased_128_rte
03/25/2025 13:49:03 - INFO - __main__ -   ***** Running evaluation  *****
03/25/2025 13:49:03 - INFO - __main__ -     Num examples = 277
03/25/2025 13:49:03 - INFO - __main__ -     Batch size = 8
03/25/2025 13:49:03 - INFO - __main__ -   loss: 0.6792739629745483
03/25/2025 13:49:04 - INFO - __main__ -   loss: 0.6594865918159485
03/25/2025 13:49:04 - INFO - __main__ -   loss: 0.627860963344574
03/25/2025 13:49:04 - INFO - __main__ -   loss: 0.7215308547019958
03/25/2025 13:49:05 - INFO - __main__ -   loss: 0.7119660973548889
03/25/2025 13:49:05 - INFO - __main__ -   loss: 0.6950995326042175
03/25/2025 13:49:05 - INFO - __main__ -   loss: 0.6862902641296387
03/25/2025 13:49:06 - INFO - __main__ -   loss: 0.6751022338867188
03/25/2025 13:49:06 - INFO - __main__ -   loss: 0.6292954683303833
03/25/2025 13:49:06 - INFO - __main__ -   loss: 0.7162505388259888
03/25/2025 13:49:07 - INFO - __main__ -   loss: 0.6872202754020691
03/25/2025 13:49:07 - INFO - __main__ -   loss: 0.7055076360702515
03/25/2025 13:49:08 - INFO - __main__ -   loss: 0.6538232564926147
03/25/2025 13:49:08 - INFO - __main__ -   loss: 0.6092687845230103
03/25/2025 13:49:08 - INFO - __main__ -   loss: 0.6504174470901489
03/25/2025 13:49:09 - INFO - __main__ -   loss: 0.7686682939529419
03/25/2025 13:49:09 - INFO - __main__ -   loss: 0.6355127096176147
03/25/2025 13:49:09 - INFO - __main__ -   loss: 0.6749213933944702
03/25/2025 13:49:10 - INFO - __main__ -   loss: 0.6691347360610962
03/25/2025 13:49:10 - INFO - __main__ -   loss: 0.6421696543693542
03/25/2025 13:49:10 - INFO - __main__ -   loss: 0.7326954007148743
03/25/2025 13:49:11 - INFO - __main__ -   loss: 0.6275437474250793
03/25/2025 13:49:11 - INFO - __main__ -   loss: 0.6745201945304871
03/25/2025 13:49:11 - INFO - __main__ -   loss: 0.6563470363616943
03/25/2025 13:49:12 - INFO - __main__ -   loss: 0.7076627016067505
03/25/2025 13:49:12 - INFO - __main__ -   loss: 0.6605845093727112
03/25/2025 13:49:12 - INFO - __main__ -   loss: 0.689466118812561
03/25/2025 13:49:13 - INFO - __main__ -   loss: 0.7039375901222229
03/25/2025 13:49:13 - INFO - __main__ -   loss: 0.6192373037338257
03/25/2025 13:49:13 - INFO - __main__ -   loss: 0.7024820446968079
03/25/2025 13:49:14 - INFO - __main__ -   loss: 0.6923796534538269
03/25/2025 13:49:14 - INFO - __main__ -   loss: 0.6996857523918152
03/25/2025 13:49:14 - INFO - __main__ -   loss: 0.6295850872993469
03/25/2025 13:49:15 - INFO - __main__ -   loss: 0.6898555755615234
03/25/2025 13:49:15 - INFO - __main__ -   loss: 0.6182767748832703
03/25/2025 13:49:15 - INFO - __main__ -   ***** Eval results  *****
03/25/2025 13:49:15 - INFO - __main__ -     acc = 0.5848375451263538
