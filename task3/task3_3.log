03/25/2025 13:25:01 - WARNING - __main__ -   Process rank: 3, device: cpu, distributed training: True, 16-bits training: False
03/25/2025 13:25:10 - INFO - pytorch_transformers.modeling_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /users/yc6206/.cache/torch/pytorch_transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.9da767be51e1327499df13488672789394e2ca38b877837e52618a67d7002391
03/25/2025 13:25:10 - INFO - pytorch_transformers.modeling_utils -   Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": "rte",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "pad_token_id": 0,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28996
}

03/25/2025 13:25:10 - INFO - pytorch_transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /users/yc6206/.cache/torch/pytorch_transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1
03/25/2025 13:25:10 - INFO - pytorch_transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at /users/yc6206/.cache/torch/pytorch_transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2
03/25/2025 13:25:19 - INFO - pytorch_transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
03/25/2025 13:25:19 - INFO - pytorch_transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
03/25/2025 13:25:22 - INFO - __main__ -   Training/evaluation parameters Namespace(data_dir='/proj/cos568proj2-PG0/glue_data/RTE', model_type='bert', model_name_or_path='bert-base-cased', task_name='rte', output_dir='/tmp/RTE/', config_name='', tokenizer_name='', cache_dir='', max_seq_length=128, do_train=True, do_eval=True, do_lower_case=False, per_device_train_batch_size=16, per_device_eval_batch_size=8, gradient_accumulation_steps=1, learning_rate=2e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=1.0, max_steps=-1, warmup_steps=0, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=42, fp16=False, fp16_opt_level='O1', local_rank=3, master_ip='10.10.1.2', master_port='12345', world_size=4, device=device(type='cpu'), n_gpu=0, output_mode='classification')
03/25/2025 13:25:22 - INFO - __main__ -   Loading features from cached file /proj/cos568proj2-PG0/glue_data/RTE/cached_train_bert-base-cased_128_rte
03/25/2025 13:25:22 - INFO - __main__ -   ***** Running training *****
03/25/2025 13:25:22 - INFO - __main__ -     Num examples = 2490
03/25/2025 13:25:22 - INFO - __main__ -     Num Epochs = 1
03/25/2025 13:25:22 - INFO - __main__ -     Instantaneous batch size per device = 16
03/25/2025 13:25:22 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 64
03/25/2025 13:25:22 - INFO - __main__ -     Gradient Accumulation steps = 1
03/25/2025 13:25:22 - INFO - __main__ -     Total optimization steps = 39
03/25/2025 13:25:28 - INFO - __main__ -   Time: 5.288130204000481
03/25/2025 13:25:31 - INFO - __main__ -   Time: 3.8117062820001593
03/25/2025 13:25:35 - INFO - __main__ -   Time: 3.174494570001116
03/25/2025 13:25:38 - INFO - __main__ -   Time: 3.1779013319992373
03/25/2025 13:25:41 - INFO - __main__ -   Time: 3.094786915000441
03/25/2025 13:25:44 - INFO - __main__ -   Time: 3.2196760099996027
03/25/2025 13:25:47 - INFO - __main__ -   Time: 2.955233265000061
03/25/2025 13:25:50 - INFO - __main__ -   Time: 2.997627085000204
03/25/2025 13:25:53 - INFO - __main__ -   Time: 3.117945411000619
03/25/2025 13:25:56 - INFO - __main__ -   Time: 2.7377948180001113
03/25/2025 13:25:59 - INFO - __main__ -   Time: 2.796509670000887
03/25/2025 13:26:01 - INFO - __main__ -   Time: 2.730378230999122
03/25/2025 13:26:04 - INFO - __main__ -   Time: 2.8073917849997088
03/25/2025 13:26:07 - INFO - __main__ -   Time: 2.7487357770005474
03/25/2025 13:26:10 - INFO - __main__ -   Time: 2.8689803000015672
03/25/2025 13:26:13 - INFO - __main__ -   Time: 2.8517006290003337
03/25/2025 13:26:15 - INFO - __main__ -   Time: 2.7660338099994988
03/25/2025 13:26:18 - INFO - __main__ -   Time: 2.6946353439998347
03/25/2025 13:26:21 - INFO - __main__ -   Time: 2.8615394060016115
03/25/2025 13:26:24 - INFO - __main__ -   Time: 2.6773928299990075
03/25/2025 13:26:26 - INFO - __main__ -   Time: 2.5862001170007716
03/25/2025 13:26:29 - INFO - __main__ -   Time: 2.5961166140004934
03/25/2025 13:26:32 - INFO - __main__ -   Time: 2.668569891000516
03/25/2025 13:26:34 - INFO - __main__ -   Time: 2.6703761650005617
03/25/2025 13:26:37 - INFO - __main__ -   Time: 2.728580545999648
03/25/2025 13:26:40 - INFO - __main__ -   Time: 2.8545154570001614
03/25/2025 13:26:42 - INFO - __main__ -   Time: 2.6230354920007812
03/25/2025 13:26:45 - INFO - __main__ -   Time: 2.858403709000413
03/25/2025 13:26:48 - INFO - __main__ -   Time: 2.593413310998585
03/25/2025 13:26:50 - INFO - __main__ -   Time: 2.632820291999451
03/25/2025 13:26:53 - INFO - __main__ -   Time: 2.6297220819997165
03/25/2025 13:26:56 - INFO - __main__ -   Time: 2.6823673979997693
03/25/2025 13:26:58 - INFO - __main__ -   Time: 2.6430542360012623
03/25/2025 13:27:01 - INFO - __main__ -   Time: 2.6457367969996994
03/25/2025 13:27:04 - INFO - __main__ -   Time: 2.6929859390002093
03/25/2025 13:27:06 - INFO - __main__ -   Time: 2.6200053619995742
03/25/2025 13:27:09 - INFO - __main__ -   Time: 2.6163846380004543
03/25/2025 13:27:12 - INFO - __main__ -   Time: 2.5842131089993927
03/25/2025 13:27:14 - INFO - __main__ -   Time: 2.549036149999665
03/25/2025 13:27:14 - INFO - __main__ -   Loading features from cached file /proj/cos568proj2-PG0/glue_data/RTE/cached_dev_bert-base-cased_128_rte
03/25/2025 13:27:14 - INFO - __main__ -   ***** Running evaluation  *****
03/25/2025 13:27:14 - INFO - __main__ -     Num examples = 277
03/25/2025 13:27:14 - INFO - __main__ -     Batch size = 8
03/25/2025 13:27:15 - INFO - __main__ -   loss: 0.6871426701545715
03/25/2025 13:27:15 - INFO - __main__ -   loss: 0.6570183634757996
03/25/2025 13:27:15 - INFO - __main__ -   loss: 0.6268364787101746
03/25/2025 13:27:16 - INFO - __main__ -   loss: 0.6819298267364502
03/25/2025 13:27:16 - INFO - __main__ -   loss: 0.6876116394996643
03/25/2025 13:27:16 - INFO - __main__ -   loss: 0.7114978432655334
03/25/2025 13:27:17 - INFO - __main__ -   loss: 0.6794167160987854
03/25/2025 13:27:17 - INFO - __main__ -   loss: 0.6625320911407471
03/25/2025 13:27:17 - INFO - __main__ -   loss: 0.6569633483886719
03/25/2025 13:27:18 - INFO - __main__ -   loss: 0.7240930199623108
03/25/2025 13:27:18 - INFO - __main__ -   loss: 0.6765318512916565
03/25/2025 13:27:18 - INFO - __main__ -   loss: 0.7123445868492126
03/25/2025 13:27:19 - INFO - __main__ -   loss: 0.6848376393318176
03/25/2025 13:27:19 - INFO - __main__ -   loss: 0.6297593712806702
03/25/2025 13:27:20 - INFO - __main__ -   loss: 0.6256791353225708
03/25/2025 13:27:20 - INFO - __main__ -   loss: 0.7444140911102295
03/25/2025 13:27:20 - INFO - __main__ -   loss: 0.6474671959877014
03/25/2025 13:27:21 - INFO - __main__ -   loss: 0.6614517569541931
03/25/2025 13:27:21 - INFO - __main__ -   loss: 0.6590377688407898
03/25/2025 13:27:21 - INFO - __main__ -   loss: 0.6621359586715698
03/25/2025 13:27:22 - INFO - __main__ -   loss: 0.7446861863136292
03/25/2025 13:27:22 - INFO - __main__ -   loss: 0.6374024748802185
03/25/2025 13:27:22 - INFO - __main__ -   loss: 0.6686539649963379
03/25/2025 13:27:23 - INFO - __main__ -   loss: 0.7021002769470215
03/25/2025 13:27:23 - INFO - __main__ -   loss: 0.6892089247703552
03/25/2025 13:27:23 - INFO - __main__ -   loss: 0.6589744091033936
03/25/2025 13:27:24 - INFO - __main__ -   loss: 0.6862251162528992
03/25/2025 13:27:24 - INFO - __main__ -   loss: 0.7014425992965698
03/25/2025 13:27:24 - INFO - __main__ -   loss: 0.6073501110076904
03/25/2025 13:27:25 - INFO - __main__ -   loss: 0.6942214369773865
03/25/2025 13:27:25 - INFO - __main__ -   loss: 0.6688443422317505
03/25/2025 13:27:25 - INFO - __main__ -   loss: 0.6826649904251099
03/25/2025 13:27:26 - INFO - __main__ -   loss: 0.6384890079498291
03/25/2025 13:27:26 - INFO - __main__ -   loss: 0.666668713092804
03/25/2025 13:27:26 - INFO - __main__ -   loss: 0.6204879879951477
03/25/2025 13:27:26 - INFO - __main__ -   ***** Eval results  *****
03/25/2025 13:27:26 - INFO - __main__ -     acc = 0.5956678700361011
03/25/2025 13:27:26 - INFO - __main__ -   Average time (excluding 1st iteration): 2.8043684414474948
03/25/2025 13:27:26 - INFO - __main__ -   All losses: [0.7816948890686035, 0.6278265714645386, 0.6490244269371033, 0.8096599578857422, 0.7189723253250122, 0.6283941864967346, 0.768462598323822, 0.7229831218719482, 0.735059916973114, 0.7035637497901917, 0.7237244844436646, 0.7117440104484558, 0.7285852432250977, 0.6834372878074646, 0.7146952152252197, 0.6873072385787964, 0.7011131644248962, 0.6287683844566345, 0.6770135164260864, 0.6668999791145325, 0.6349842548370361, 0.6867968440055847, 0.695724368095398, 0.6979570388793945, 0.7452324032783508, 0.6769335269927979, 0.6851585507392883, 0.6649702787399292, 0.6692674160003662, 0.6298605799674988, 0.6928175687789917, 0.7050239443778992, 0.6678736805915833, 0.7052376866340637, 0.6904240846633911, 0.7078969478607178, 0.6607024669647217, 0.6969081163406372, 0.6470774412155151]
03/25/2025 13:27:26 - INFO - __main__ -    global_step = 39, average loss = 0.6930712171089954
03/25/2025 13:27:26 - INFO - __main__ -   Loading features from cached file /proj/cos568proj2-PG0/glue_data/RTE/cached_dev_bert-base-cased_128_rte
03/25/2025 13:27:27 - INFO - __main__ -   ***** Running evaluation  *****
03/25/2025 13:27:27 - INFO - __main__ -     Num examples = 277
03/25/2025 13:27:27 - INFO - __main__ -     Batch size = 8
03/25/2025 13:27:27 - INFO - __main__ -   loss: 0.6871426701545715
03/25/2025 13:27:27 - INFO - __main__ -   loss: 0.6570183634757996
03/25/2025 13:27:28 - INFO - __main__ -   loss: 0.6268364787101746
03/25/2025 13:27:28 - INFO - __main__ -   loss: 0.6819298267364502
03/25/2025 13:27:28 - INFO - __main__ -   loss: 0.6876116394996643
03/25/2025 13:27:29 - INFO - __main__ -   loss: 0.7114978432655334
03/25/2025 13:27:29 - INFO - __main__ -   loss: 0.6794167160987854
03/25/2025 13:27:29 - INFO - __main__ -   loss: 0.6625320911407471
03/25/2025 13:27:30 - INFO - __main__ -   loss: 0.6569633483886719
03/25/2025 13:27:30 - INFO - __main__ -   loss: 0.7240930199623108
03/25/2025 13:27:30 - INFO - __main__ -   loss: 0.6765318512916565
03/25/2025 13:27:31 - INFO - __main__ -   loss: 0.7123445868492126
03/25/2025 13:27:31 - INFO - __main__ -   loss: 0.6848376393318176
03/25/2025 13:27:31 - INFO - __main__ -   loss: 0.6297593712806702
03/25/2025 13:27:32 - INFO - __main__ -   loss: 0.6256791353225708
03/25/2025 13:27:32 - INFO - __main__ -   loss: 0.7444140911102295
03/25/2025 13:27:32 - INFO - __main__ -   loss: 0.6474671959877014
03/25/2025 13:27:33 - INFO - __main__ -   loss: 0.6614517569541931
03/25/2025 13:27:33 - INFO - __main__ -   loss: 0.6590377688407898
03/25/2025 13:27:33 - INFO - __main__ -   loss: 0.6621359586715698
03/25/2025 13:27:34 - INFO - __main__ -   loss: 0.7446861863136292
03/25/2025 13:27:34 - INFO - __main__ -   loss: 0.6374024748802185
03/25/2025 13:27:34 - INFO - __main__ -   loss: 0.6686539649963379
03/25/2025 13:27:35 - INFO - __main__ -   loss: 0.7021002769470215
03/25/2025 13:27:35 - INFO - __main__ -   loss: 0.6892089247703552
03/25/2025 13:27:36 - INFO - __main__ -   loss: 0.6589744091033936
03/25/2025 13:27:36 - INFO - __main__ -   loss: 0.6862251162528992
03/25/2025 13:27:36 - INFO - __main__ -   loss: 0.7014425992965698
03/25/2025 13:27:37 - INFO - __main__ -   loss: 0.6073501110076904
03/25/2025 13:27:37 - INFO - __main__ -   loss: 0.6942214369773865
03/25/2025 13:27:37 - INFO - __main__ -   loss: 0.6688443422317505
03/25/2025 13:27:38 - INFO - __main__ -   loss: 0.6826649904251099
03/25/2025 13:27:38 - INFO - __main__ -   loss: 0.6384890079498291
03/25/2025 13:27:38 - INFO - __main__ -   loss: 0.666668713092804
03/25/2025 13:27:38 - INFO - __main__ -   loss: 0.6204879879951477
03/25/2025 13:27:39 - INFO - __main__ -   ***** Eval results  *****
03/25/2025 13:27:39 - INFO - __main__ -     acc = 0.5956678700361011
