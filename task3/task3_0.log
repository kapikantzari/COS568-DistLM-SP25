03/25/2025 13:25:01 - WARNING - __main__ -   Process rank: 0, device: cpu, distributed training: True, 16-bits training: False
03/25/2025 13:25:01 - INFO - pytorch_transformers.modeling_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /users/yc6206/.cache/torch/pytorch_transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.9da767be51e1327499df13488672789394e2ca38b877837e52618a67d7002391
03/25/2025 13:25:01 - INFO - pytorch_transformers.modeling_utils -   Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": "rte",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "pad_token_id": 0,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28996
}

03/25/2025 13:25:01 - INFO - pytorch_transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /users/yc6206/.cache/torch/pytorch_transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1
03/25/2025 13:25:01 - INFO - pytorch_transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at /users/yc6206/.cache/torch/pytorch_transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2
03/25/2025 13:25:10 - INFO - pytorch_transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
03/25/2025 13:25:10 - INFO - pytorch_transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
03/25/2025 13:25:22 - INFO - __main__ -   Training/evaluation parameters Namespace(data_dir='/proj/cos568proj2-PG0/glue_data/RTE', model_type='bert', model_name_or_path='bert-base-cased', task_name='rte', output_dir='/tmp/RTE/', config_name='', tokenizer_name='', cache_dir='', max_seq_length=128, do_train=True, do_eval=True, do_lower_case=False, per_device_train_batch_size=16, per_device_eval_batch_size=8, gradient_accumulation_steps=1, learning_rate=2e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=1.0, max_steps=-1, warmup_steps=0, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=42, fp16=False, fp16_opt_level='O1', local_rank=0, master_ip='10.10.1.2', master_port='12345', world_size=4, device=device(type='cpu'), n_gpu=0, output_mode='classification')
03/25/2025 13:25:22 - INFO - __main__ -   Loading features from cached file /proj/cos568proj2-PG0/glue_data/RTE/cached_train_bert-base-cased_128_rte
03/25/2025 13:25:22 - INFO - __main__ -   ***** Running training *****
03/25/2025 13:25:22 - INFO - __main__ -     Num examples = 2490
03/25/2025 13:25:22 - INFO - __main__ -     Num Epochs = 1
03/25/2025 13:25:22 - INFO - __main__ -     Instantaneous batch size per device = 16
03/25/2025 13:25:22 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 64
03/25/2025 13:25:22 - INFO - __main__ -     Gradient Accumulation steps = 1
03/25/2025 13:25:22 - INFO - __main__ -     Total optimization steps = 39
03/25/2025 13:25:28 - INFO - __main__ -   Time: 5.504711625000709
03/25/2025 13:25:31 - INFO - __main__ -   Time: 3.772002302001056
03/25/2025 13:25:34 - INFO - __main__ -   Time: 3.145623013000659
03/25/2025 13:25:38 - INFO - __main__ -   Time: 3.1509794060002605
03/25/2025 13:25:41 - INFO - __main__ -   Time: 3.158220060000531
03/25/2025 13:25:44 - INFO - __main__ -   Time: 3.22866505499951
03/25/2025 13:25:47 - INFO - __main__ -   Time: 2.937779595999018
03/25/2025 13:25:50 - INFO - __main__ -   Time: 2.9771688419987186
03/25/2025 13:25:53 - INFO - __main__ -   Time: 3.1309380380007497
03/25/2025 13:25:56 - INFO - __main__ -   Time: 2.735910645000331
03/25/2025 13:25:59 - INFO - __main__ -   Time: 2.8060893259989825
03/25/2025 13:26:01 - INFO - __main__ -   Time: 2.7367720549991645
03/25/2025 13:26:04 - INFO - __main__ -   Time: 2.7877738759998465
03/25/2025 13:26:07 - INFO - __main__ -   Time: 2.7609667029992124
03/25/2025 13:26:10 - INFO - __main__ -   Time: 2.8548692790009227
03/25/2025 13:26:13 - INFO - __main__ -   Time: 2.8872358329990675
03/25/2025 13:26:15 - INFO - __main__ -   Time: 2.722551779999776
03/25/2025 13:26:18 - INFO - __main__ -   Time: 2.7155728449997696
03/25/2025 13:26:21 - INFO - __main__ -   Time: 2.8735438719995727
03/25/2025 13:26:24 - INFO - __main__ -   Time: 2.659840215001168
03/25/2025 13:26:26 - INFO - __main__ -   Time: 2.58869346100073
03/25/2025 13:26:29 - INFO - __main__ -   Time: 2.5947482789997593
03/25/2025 13:26:32 - INFO - __main__ -   Time: 2.6745669079991785
03/25/2025 13:26:34 - INFO - __main__ -   Time: 2.6622262170003523
03/25/2025 13:26:37 - INFO - __main__ -   Time: 2.715725398000359
03/25/2025 13:26:40 - INFO - __main__ -   Time: 2.8840433819987084
03/25/2025 13:26:42 - INFO - __main__ -   Time: 2.602395093999803
03/25/2025 13:26:45 - INFO - __main__ -   Time: 2.833299531999728
03/25/2025 13:26:48 - INFO - __main__ -   Time: 2.626269690999834
03/25/2025 13:26:50 - INFO - __main__ -   Time: 2.627675775998796
03/25/2025 13:26:53 - INFO - __main__ -   Time: 2.613562702001218
03/25/2025 13:26:56 - INFO - __main__ -   Time: 2.70016558899988
03/25/2025 13:26:58 - INFO - __main__ -   Time: 2.641771418000644
03/25/2025 13:27:01 - INFO - __main__ -   Time: 2.6469392760009214
03/25/2025 13:27:04 - INFO - __main__ -   Time: 2.6801792990008835
03/25/2025 13:27:06 - INFO - __main__ -   Time: 2.6196791700003814
03/25/2025 13:27:09 - INFO - __main__ -   Time: 2.6236503579984856
03/25/2025 13:27:12 - INFO - __main__ -   Time: 2.5758830510003463
03/25/2025 13:27:14 - INFO - __main__ -   Time: 2.5608441330005007
03/25/2025 13:27:14 - INFO - __main__ -   Loading features from cached file /proj/cos568proj2-PG0/glue_data/RTE/cached_dev_bert-base-cased_128_rte
03/25/2025 13:27:14 - INFO - __main__ -   ***** Running evaluation  *****
03/25/2025 13:27:14 - INFO - __main__ -     Num examples = 277
03/25/2025 13:27:14 - INFO - __main__ -     Batch size = 8
03/25/2025 13:27:15 - INFO - __main__ -   loss: 0.6871426701545715
03/25/2025 13:27:15 - INFO - __main__ -   loss: 0.6570183634757996
03/25/2025 13:27:15 - INFO - __main__ -   loss: 0.6268364787101746
03/25/2025 13:27:16 - INFO - __main__ -   loss: 0.6819298267364502
03/25/2025 13:27:16 - INFO - __main__ -   loss: 0.6876116394996643
03/25/2025 13:27:16 - INFO - __main__ -   loss: 0.7114978432655334
03/25/2025 13:27:17 - INFO - __main__ -   loss: 0.6794167160987854
03/25/2025 13:27:17 - INFO - __main__ -   loss: 0.6625320911407471
03/25/2025 13:27:17 - INFO - __main__ -   loss: 0.6569633483886719
03/25/2025 13:27:18 - INFO - __main__ -   loss: 0.7240930199623108
03/25/2025 13:27:18 - INFO - __main__ -   loss: 0.6765318512916565
03/25/2025 13:27:18 - INFO - __main__ -   loss: 0.7123445868492126
03/25/2025 13:27:19 - INFO - __main__ -   loss: 0.6848376393318176
03/25/2025 13:27:19 - INFO - __main__ -   loss: 0.6297593712806702
03/25/2025 13:27:19 - INFO - __main__ -   loss: 0.6256791353225708
03/25/2025 13:27:20 - INFO - __main__ -   loss: 0.7444140911102295
03/25/2025 13:27:20 - INFO - __main__ -   loss: 0.6474671959877014
03/25/2025 13:27:20 - INFO - __main__ -   loss: 0.6614517569541931
03/25/2025 13:27:21 - INFO - __main__ -   loss: 0.6590377688407898
03/25/2025 13:27:21 - INFO - __main__ -   loss: 0.6621359586715698
03/25/2025 13:27:21 - INFO - __main__ -   loss: 0.7446861863136292
03/25/2025 13:27:22 - INFO - __main__ -   loss: 0.6374024748802185
03/25/2025 13:27:22 - INFO - __main__ -   loss: 0.6686539649963379
03/25/2025 13:27:22 - INFO - __main__ -   loss: 0.7021002769470215
03/25/2025 13:27:23 - INFO - __main__ -   loss: 0.6892089247703552
03/25/2025 13:27:23 - INFO - __main__ -   loss: 0.6589744091033936
03/25/2025 13:27:23 - INFO - __main__ -   loss: 0.6862251162528992
03/25/2025 13:27:24 - INFO - __main__ -   loss: 0.7014425992965698
03/25/2025 13:27:24 - INFO - __main__ -   loss: 0.6073501110076904
03/25/2025 13:27:25 - INFO - __main__ -   loss: 0.6942214369773865
03/25/2025 13:27:25 - INFO - __main__ -   loss: 0.6688443422317505
03/25/2025 13:27:25 - INFO - __main__ -   loss: 0.6826649904251099
03/25/2025 13:27:26 - INFO - __main__ -   loss: 0.6384890079498291
03/25/2025 13:27:26 - INFO - __main__ -   loss: 0.666668713092804
03/25/2025 13:27:26 - INFO - __main__ -   loss: 0.6204879879951477
03/25/2025 13:27:26 - INFO - __main__ -   ***** Eval results  *****
03/25/2025 13:27:26 - INFO - __main__ -     acc = 0.5956678700361011
03/25/2025 13:27:26 - INFO - __main__ -   Average time (excluding 1st iteration): 2.803021617763127
03/25/2025 13:27:26 - INFO - __main__ -   All losses: [1.0180578231811523, 0.702133059501648, 0.8006546497344971, 0.7554677724838257, 0.7261958122253418, 0.6844937801361084, 0.7229129076004028, 0.7229397296905518, 0.6792713403701782, 0.6678263545036316, 0.6376899480819702, 0.6937162280082703, 0.6267299652099609, 0.7270932197570801, 0.7341051697731018, 0.6978049874305725, 0.6159424781799316, 0.6287010312080383, 0.6552484035491943, 0.6906989812850952, 0.6552271842956543, 0.7248730659484863, 0.6859298944473267, 0.7024665474891663, 0.6970337629318237, 0.6748731732368469, 0.6698351502418518, 0.7199046611785889, 0.7045708298683167, 0.6246534585952759, 0.6796866059303284, 0.712964653968811, 0.6121959686279297, 0.7389938831329346, 0.7091907262802124, 0.6937378644943237, 0.7032169699668884, 0.7141276597976685, 0.6246801614761353]
03/25/2025 13:27:26 - INFO - __main__ -    global_step = 39, average loss = 0.6983550221492083
03/25/2025 13:27:26 - INFO - __main__ -   Loading features from cached file /proj/cos568proj2-PG0/glue_data/RTE/cached_dev_bert-base-cased_128_rte
03/25/2025 13:27:27 - INFO - __main__ -   ***** Running evaluation  *****
03/25/2025 13:27:27 - INFO - __main__ -     Num examples = 277
03/25/2025 13:27:27 - INFO - __main__ -     Batch size = 8
03/25/2025 13:27:27 - INFO - __main__ -   loss: 0.6871426701545715
03/25/2025 13:27:27 - INFO - __main__ -   loss: 0.6570183634757996
03/25/2025 13:27:28 - INFO - __main__ -   loss: 0.6268364787101746
03/25/2025 13:27:28 - INFO - __main__ -   loss: 0.6819298267364502
03/25/2025 13:27:28 - INFO - __main__ -   loss: 0.6876116394996643
03/25/2025 13:27:29 - INFO - __main__ -   loss: 0.7114978432655334
03/25/2025 13:27:29 - INFO - __main__ -   loss: 0.6794167160987854
03/25/2025 13:27:29 - INFO - __main__ -   loss: 0.6625320911407471
03/25/2025 13:27:30 - INFO - __main__ -   loss: 0.6569633483886719
03/25/2025 13:27:30 - INFO - __main__ -   loss: 0.7240930199623108
03/25/2025 13:27:30 - INFO - __main__ -   loss: 0.6765318512916565
03/25/2025 13:27:31 - INFO - __main__ -   loss: 0.7123445868492126
03/25/2025 13:27:31 - INFO - __main__ -   loss: 0.6848376393318176
03/25/2025 13:27:31 - INFO - __main__ -   loss: 0.6297593712806702
03/25/2025 13:27:32 - INFO - __main__ -   loss: 0.6256791353225708
03/25/2025 13:27:32 - INFO - __main__ -   loss: 0.7444140911102295
03/25/2025 13:27:32 - INFO - __main__ -   loss: 0.6474671959877014
03/25/2025 13:27:33 - INFO - __main__ -   loss: 0.6614517569541931
03/25/2025 13:27:33 - INFO - __main__ -   loss: 0.6590377688407898
03/25/2025 13:27:33 - INFO - __main__ -   loss: 0.6621359586715698
03/25/2025 13:27:34 - INFO - __main__ -   loss: 0.7446861863136292
03/25/2025 13:27:34 - INFO - __main__ -   loss: 0.6374024748802185
03/25/2025 13:27:34 - INFO - __main__ -   loss: 0.6686539649963379
03/25/2025 13:27:35 - INFO - __main__ -   loss: 0.7021002769470215
03/25/2025 13:27:35 - INFO - __main__ -   loss: 0.6892089247703552
03/25/2025 13:27:35 - INFO - __main__ -   loss: 0.6589744091033936
03/25/2025 13:27:36 - INFO - __main__ -   loss: 0.6862251162528992
03/25/2025 13:27:36 - INFO - __main__ -   loss: 0.7014425992965698
03/25/2025 13:27:36 - INFO - __main__ -   loss: 0.6073501110076904
03/25/2025 13:27:37 - INFO - __main__ -   loss: 0.6942214369773865
03/25/2025 13:27:37 - INFO - __main__ -   loss: 0.6688443422317505
03/25/2025 13:27:38 - INFO - __main__ -   loss: 0.6826649904251099
03/25/2025 13:27:38 - INFO - __main__ -   loss: 0.6384890079498291
03/25/2025 13:27:38 - INFO - __main__ -   loss: 0.666668713092804
03/25/2025 13:27:38 - INFO - __main__ -   loss: 0.6204879879951477
03/25/2025 13:27:38 - INFO - __main__ -   ***** Eval results  *****
03/25/2025 13:27:38 - INFO - __main__ -     acc = 0.5956678700361011
