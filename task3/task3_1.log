03/25/2025 13:25:01 - WARNING - __main__ -   Process rank: 1, device: cpu, distributed training: True, 16-bits training: False
03/25/2025 13:25:10 - INFO - pytorch_transformers.modeling_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /users/yc6206/.cache/torch/pytorch_transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.9da767be51e1327499df13488672789394e2ca38b877837e52618a67d7002391
03/25/2025 13:25:10 - INFO - pytorch_transformers.modeling_utils -   Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": "rte",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "pad_token_id": 0,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28996
}

03/25/2025 13:25:10 - INFO - pytorch_transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /users/yc6206/.cache/torch/pytorch_transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1
03/25/2025 13:25:10 - INFO - pytorch_transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at /users/yc6206/.cache/torch/pytorch_transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2
03/25/2025 13:25:19 - INFO - pytorch_transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
03/25/2025 13:25:19 - INFO - pytorch_transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
03/25/2025 13:25:22 - INFO - __main__ -   Training/evaluation parameters Namespace(data_dir='/proj/cos568proj2-PG0/glue_data/RTE', model_type='bert', model_name_or_path='bert-base-cased', task_name='rte', output_dir='/tmp/RTE/', config_name='', tokenizer_name='', cache_dir='', max_seq_length=128, do_train=True, do_eval=True, do_lower_case=False, per_device_train_batch_size=16, per_device_eval_batch_size=8, gradient_accumulation_steps=1, learning_rate=2e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=1.0, max_steps=-1, warmup_steps=0, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=42, fp16=False, fp16_opt_level='O1', local_rank=1, master_ip='10.10.1.2', master_port='12345', world_size=4, device=device(type='cpu'), n_gpu=0, output_mode='classification')
03/25/2025 13:25:22 - INFO - __main__ -   Loading features from cached file /proj/cos568proj2-PG0/glue_data/RTE/cached_train_bert-base-cased_128_rte
03/25/2025 13:25:22 - INFO - __main__ -   ***** Running training *****
03/25/2025 13:25:22 - INFO - __main__ -     Num examples = 2490
03/25/2025 13:25:22 - INFO - __main__ -     Num Epochs = 1
03/25/2025 13:25:22 - INFO - __main__ -     Instantaneous batch size per device = 16
03/25/2025 13:25:22 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 64
03/25/2025 13:25:22 - INFO - __main__ -     Gradient Accumulation steps = 1
03/25/2025 13:25:22 - INFO - __main__ -     Total optimization steps = 39
03/25/2025 13:25:28 - INFO - __main__ -   Time: 5.32320645999971
03/25/2025 13:25:31 - INFO - __main__ -   Time: 3.7979142379990662
03/25/2025 13:25:35 - INFO - __main__ -   Time: 3.11828975500066
03/25/2025 13:25:38 - INFO - __main__ -   Time: 3.211637601998518
03/25/2025 13:25:41 - INFO - __main__ -   Time: 3.1046016380005312
03/25/2025 13:25:44 - INFO - __main__ -   Time: 3.2208001849994616
03/25/2025 13:25:47 - INFO - __main__ -   Time: 2.9393026279994956
03/25/2025 13:25:50 - INFO - __main__ -   Time: 2.937652544998855
03/25/2025 13:25:53 - INFO - __main__ -   Time: 3.152773032999903
03/25/2025 13:25:56 - INFO - __main__ -   Time: 2.7537138920015423
03/25/2025 13:25:59 - INFO - __main__ -   Time: 2.7990822960000514
03/25/2025 13:26:01 - INFO - __main__ -   Time: 2.7414738679999573
03/25/2025 13:26:04 - INFO - __main__ -   Time: 2.7960314880001533
03/25/2025 13:26:07 - INFO - __main__ -   Time: 2.758678714999405
03/25/2025 13:26:10 - INFO - __main__ -   Time: 2.8682044739998673
03/25/2025 13:26:13 - INFO - __main__ -   Time: 2.84619087000101
03/25/2025 13:26:15 - INFO - __main__ -   Time: 2.728544644000067
03/25/2025 13:26:18 - INFO - __main__ -   Time: 2.7255462419998366
03/25/2025 13:26:21 - INFO - __main__ -   Time: 2.898703471000772
03/25/2025 13:26:24 - INFO - __main__ -   Time: 2.636573600999327
03/25/2025 13:26:26 - INFO - __main__ -   Time: 2.5996979190003913
03/25/2025 13:26:29 - INFO - __main__ -   Time: 2.5864509160001035
03/25/2025 13:26:32 - INFO - __main__ -   Time: 2.6695449569997436
03/25/2025 13:26:34 - INFO - __main__ -   Time: 2.684925067000222
03/25/2025 13:26:37 - INFO - __main__ -   Time: 2.7114352620010322
03/25/2025 13:26:40 - INFO - __main__ -   Time: 2.8622030290007388
03/25/2025 13:26:42 - INFO - __main__ -   Time: 2.614306026000122
03/25/2025 13:26:45 - INFO - __main__ -   Time: 2.8349287519995414
03/25/2025 13:26:48 - INFO - __main__ -   Time: 2.6314386679987365
03/25/2025 13:26:50 - INFO - __main__ -   Time: 2.6264084310005273
03/25/2025 13:26:53 - INFO - __main__ -   Time: 2.6175380679997033
03/25/2025 13:26:56 - INFO - __main__ -   Time: 2.698522597998817
03/25/2025 13:26:58 - INFO - __main__ -   Time: 2.63474375000078
03/25/2025 13:27:01 - INFO - __main__ -   Time: 2.6420009579996986
03/25/2025 13:27:04 - INFO - __main__ -   Time: 2.684324223000658
03/25/2025 13:27:06 - INFO - __main__ -   Time: 2.624313392998374
03/25/2025 13:27:09 - INFO - __main__ -   Time: 2.622472569999445
03/25/2025 13:27:12 - INFO - __main__ -   Time: 2.580866944999798
03/25/2025 13:27:14 - INFO - __main__ -   Time: 2.5530149480000546
03/25/2025 13:27:14 - INFO - __main__ -   Loading features from cached file /proj/cos568proj2-PG0/glue_data/RTE/cached_dev_bert-base-cased_128_rte
03/25/2025 13:27:14 - INFO - __main__ -   ***** Running evaluation  *****
03/25/2025 13:27:14 - INFO - __main__ -     Num examples = 277
03/25/2025 13:27:14 - INFO - __main__ -     Batch size = 8
03/25/2025 13:27:15 - INFO - __main__ -   loss: 0.6871426701545715
03/25/2025 13:27:15 - INFO - __main__ -   loss: 0.6570183634757996
03/25/2025 13:27:15 - INFO - __main__ -   loss: 0.6268364787101746
03/25/2025 13:27:16 - INFO - __main__ -   loss: 0.6819298267364502
03/25/2025 13:27:16 - INFO - __main__ -   loss: 0.6876116394996643
03/25/2025 13:27:16 - INFO - __main__ -   loss: 0.7114978432655334
03/25/2025 13:27:17 - INFO - __main__ -   loss: 0.6794167160987854
03/25/2025 13:27:17 - INFO - __main__ -   loss: 0.6625320911407471
03/25/2025 13:27:17 - INFO - __main__ -   loss: 0.6569633483886719
03/25/2025 13:27:18 - INFO - __main__ -   loss: 0.7240930199623108
03/25/2025 13:27:18 - INFO - __main__ -   loss: 0.6765318512916565
03/25/2025 13:27:19 - INFO - __main__ -   loss: 0.7123445868492126
03/25/2025 13:27:19 - INFO - __main__ -   loss: 0.6848376393318176
03/25/2025 13:27:19 - INFO - __main__ -   loss: 0.6297593712806702
03/25/2025 13:27:20 - INFO - __main__ -   loss: 0.6256791353225708
03/25/2025 13:27:20 - INFO - __main__ -   loss: 0.7444140911102295
03/25/2025 13:27:20 - INFO - __main__ -   loss: 0.6474671959877014
03/25/2025 13:27:21 - INFO - __main__ -   loss: 0.6614517569541931
03/25/2025 13:27:21 - INFO - __main__ -   loss: 0.6590377688407898
03/25/2025 13:27:21 - INFO - __main__ -   loss: 0.6621359586715698
03/25/2025 13:27:22 - INFO - __main__ -   loss: 0.7446861863136292
03/25/2025 13:27:22 - INFO - __main__ -   loss: 0.6374024748802185
03/25/2025 13:27:22 - INFO - __main__ -   loss: 0.6686539649963379
03/25/2025 13:27:23 - INFO - __main__ -   loss: 0.7021002769470215
03/25/2025 13:27:23 - INFO - __main__ -   loss: 0.6892089247703552
03/25/2025 13:27:23 - INFO - __main__ -   loss: 0.6589744091033936
03/25/2025 13:27:24 - INFO - __main__ -   loss: 0.6862251162528992
03/25/2025 13:27:24 - INFO - __main__ -   loss: 0.7014425992965698
03/25/2025 13:27:24 - INFO - __main__ -   loss: 0.6073501110076904
03/25/2025 13:27:25 - INFO - __main__ -   loss: 0.6942214369773865
03/25/2025 13:27:25 - INFO - __main__ -   loss: 0.6688443422317505
03/25/2025 13:27:25 - INFO - __main__ -   loss: 0.6826649904251099
03/25/2025 13:27:26 - INFO - __main__ -   loss: 0.6384890079498291
03/25/2025 13:27:26 - INFO - __main__ -   loss: 0.666668713092804
03/25/2025 13:27:26 - INFO - __main__ -   loss: 0.6204879879951477
03/25/2025 13:27:26 - INFO - __main__ -   ***** Eval results  *****
03/25/2025 13:27:26 - INFO - __main__ -     acc = 0.5956678700361011
03/25/2025 13:27:26 - INFO - __main__ -   Average time (excluding 1st iteration): 2.8030224122367624
03/25/2025 13:27:26 - INFO - __main__ -   All losses: [0.7578274011611938, 0.7999069690704346, 0.8031934499740601, 0.6816916465759277, 0.7121379971504211, 0.7427650690078735, 0.6741857528686523, 0.7115065455436707, 0.6659683585166931, 0.7458406090736389, 0.6508029699325562, 0.6464335322380066, 0.7096243500709534, 0.6649474501609802, 0.7595984935760498, 0.722570538520813, 0.697807788848877, 0.6609575152397156, 0.7109946012496948, 0.6817386150360107, 0.6701485514640808, 0.6924045085906982, 0.7301046848297119, 0.651435911655426, 0.676104724407196, 0.7184137105941772, 0.6665042638778687, 0.6651604175567627, 0.6540504097938538, 0.6713438630104065, 0.6538099050521851, 0.6563214659690857, 0.7468044757843018, 0.6789729595184326, 0.723186731338501, 0.7203543186187744, 0.6678086519241333, 0.6756129264831543, 0.6382384896278381]
03/25/2025 13:27:26 - INFO - __main__ -    global_step = 39, average loss = 0.6963405288182772
03/25/2025 13:27:26 - INFO - __main__ -   Loading features from cached file /proj/cos568proj2-PG0/glue_data/RTE/cached_dev_bert-base-cased_128_rte
03/25/2025 13:27:27 - INFO - __main__ -   ***** Running evaluation  *****
03/25/2025 13:27:27 - INFO - __main__ -     Num examples = 277
03/25/2025 13:27:27 - INFO - __main__ -     Batch size = 8
03/25/2025 13:27:27 - INFO - __main__ -   loss: 0.6871426701545715
03/25/2025 13:27:27 - INFO - __main__ -   loss: 0.6570183634757996
03/25/2025 13:27:28 - INFO - __main__ -   loss: 0.6268364787101746
03/25/2025 13:27:28 - INFO - __main__ -   loss: 0.6819298267364502
03/25/2025 13:27:28 - INFO - __main__ -   loss: 0.6876116394996643
03/25/2025 13:27:29 - INFO - __main__ -   loss: 0.7114978432655334
03/25/2025 13:27:29 - INFO - __main__ -   loss: 0.6794167160987854
03/25/2025 13:27:29 - INFO - __main__ -   loss: 0.6625320911407471
03/25/2025 13:27:30 - INFO - __main__ -   loss: 0.6569633483886719
03/25/2025 13:27:30 - INFO - __main__ -   loss: 0.7240930199623108
03/25/2025 13:27:30 - INFO - __main__ -   loss: 0.6765318512916565
03/25/2025 13:27:31 - INFO - __main__ -   loss: 0.7123445868492126
03/25/2025 13:27:31 - INFO - __main__ -   loss: 0.6848376393318176
03/25/2025 13:27:31 - INFO - __main__ -   loss: 0.6297593712806702
03/25/2025 13:27:32 - INFO - __main__ -   loss: 0.6256791353225708
03/25/2025 13:27:32 - INFO - __main__ -   loss: 0.7444140911102295
03/25/2025 13:27:32 - INFO - __main__ -   loss: 0.6474671959877014
03/25/2025 13:27:33 - INFO - __main__ -   loss: 0.6614517569541931
03/25/2025 13:27:33 - INFO - __main__ -   loss: 0.6590377688407898
03/25/2025 13:27:33 - INFO - __main__ -   loss: 0.6621359586715698
03/25/2025 13:27:34 - INFO - __main__ -   loss: 0.7446861863136292
03/25/2025 13:27:34 - INFO - __main__ -   loss: 0.6374024748802185
03/25/2025 13:27:34 - INFO - __main__ -   loss: 0.6686539649963379
03/25/2025 13:27:35 - INFO - __main__ -   loss: 0.7021002769470215
03/25/2025 13:27:35 - INFO - __main__ -   loss: 0.6892089247703552
03/25/2025 13:27:35 - INFO - __main__ -   loss: 0.6589744091033936
03/25/2025 13:27:36 - INFO - __main__ -   loss: 0.6862251162528992
03/25/2025 13:27:36 - INFO - __main__ -   loss: 0.7014425992965698
03/25/2025 13:27:36 - INFO - __main__ -   loss: 0.6073501110076904
03/25/2025 13:27:37 - INFO - __main__ -   loss: 0.6942214369773865
03/25/2025 13:27:37 - INFO - __main__ -   loss: 0.6688443422317505
03/25/2025 13:27:37 - INFO - __main__ -   loss: 0.6826649904251099
03/25/2025 13:27:38 - INFO - __main__ -   loss: 0.6384890079498291
03/25/2025 13:27:38 - INFO - __main__ -   loss: 0.666668713092804
03/25/2025 13:27:38 - INFO - __main__ -   loss: 0.6204879879951477
03/25/2025 13:27:38 - INFO - __main__ -   ***** Eval results  *****
03/25/2025 13:27:38 - INFO - __main__ -     acc = 0.5956678700361011
