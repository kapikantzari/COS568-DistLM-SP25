03/25/2025 13:25:01 - WARNING - __main__ -   Process rank: 2, device: cpu, distributed training: True, 16-bits training: False
03/25/2025 13:25:10 - INFO - pytorch_transformers.modeling_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /users/yc6206/.cache/torch/pytorch_transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.9da767be51e1327499df13488672789394e2ca38b877837e52618a67d7002391
03/25/2025 13:25:10 - INFO - pytorch_transformers.modeling_utils -   Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": "rte",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "pad_token_id": 0,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28996
}

03/25/2025 13:25:10 - INFO - pytorch_transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /users/yc6206/.cache/torch/pytorch_transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1
03/25/2025 13:25:10 - INFO - pytorch_transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at /users/yc6206/.cache/torch/pytorch_transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2
03/25/2025 13:25:19 - INFO - pytorch_transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
03/25/2025 13:25:19 - INFO - pytorch_transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
03/25/2025 13:25:22 - INFO - __main__ -   Training/evaluation parameters Namespace(data_dir='/proj/cos568proj2-PG0/glue_data/RTE', model_type='bert', model_name_or_path='bert-base-cased', task_name='rte', output_dir='/tmp/RTE/', config_name='', tokenizer_name='', cache_dir='', max_seq_length=128, do_train=True, do_eval=True, do_lower_case=False, per_device_train_batch_size=16, per_device_eval_batch_size=8, gradient_accumulation_steps=1, learning_rate=2e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=1.0, max_steps=-1, warmup_steps=0, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=42, fp16=False, fp16_opt_level='O1', local_rank=2, master_ip='10.10.1.2', master_port='12345', world_size=4, device=device(type='cpu'), n_gpu=0, output_mode='classification')
03/25/2025 13:25:22 - INFO - __main__ -   Loading features from cached file /proj/cos568proj2-PG0/glue_data/RTE/cached_train_bert-base-cased_128_rte
03/25/2025 13:25:22 - INFO - __main__ -   ***** Running training *****
03/25/2025 13:25:22 - INFO - __main__ -     Num examples = 2490
03/25/2025 13:25:22 - INFO - __main__ -     Num Epochs = 1
03/25/2025 13:25:22 - INFO - __main__ -     Instantaneous batch size per device = 16
03/25/2025 13:25:22 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 64
03/25/2025 13:25:22 - INFO - __main__ -     Gradient Accumulation steps = 1
03/25/2025 13:25:22 - INFO - __main__ -     Total optimization steps = 39
03/25/2025 13:25:28 - INFO - __main__ -   Time: 5.285245912999017
03/25/2025 13:25:31 - INFO - __main__ -   Time: 3.889262933998907
03/25/2025 13:25:34 - INFO - __main__ -   Time: 3.0357349519999843
03/25/2025 13:25:38 - INFO - __main__ -   Time: 3.1829056030001084
03/25/2025 13:25:41 - INFO - __main__ -   Time: 3.1759759209999174
03/25/2025 13:25:44 - INFO - __main__ -   Time: 3.2028949769992323
03/25/2025 13:25:47 - INFO - __main__ -   Time: 2.95158739100043
03/25/2025 13:25:50 - INFO - __main__ -   Time: 2.972719348999817
03/25/2025 13:25:53 - INFO - __main__ -   Time: 3.1178644609990442
03/25/2025 13:25:56 - INFO - __main__ -   Time: 2.754489053000725
03/25/2025 13:25:59 - INFO - __main__ -   Time: 2.8233806309999636
03/25/2025 13:26:01 - INFO - __main__ -   Time: 2.6989453740006866
03/25/2025 13:26:04 - INFO - __main__ -   Time: 2.828638778999448
03/25/2025 13:26:07 - INFO - __main__ -   Time: 2.759597689000657
03/25/2025 13:26:10 - INFO - __main__ -   Time: 2.8609461289997853
03/25/2025 13:26:13 - INFO - __main__ -   Time: 2.8812824830001773
03/25/2025 13:26:15 - INFO - __main__ -   Time: 2.702660102999289
03/25/2025 13:26:18 - INFO - __main__ -   Time: 2.7144068629986577
03/25/2025 13:26:21 - INFO - __main__ -   Time: 2.8793179360000067
03/25/2025 13:26:24 - INFO - __main__ -   Time: 2.652429645000666
03/25/2025 13:26:26 - INFO - __main__ -   Time: 2.608902804999161
03/25/2025 13:26:29 - INFO - __main__ -   Time: 2.577132481999797
03/25/2025 13:26:32 - INFO - __main__ -   Time: 2.690685358000337
03/25/2025 13:26:34 - INFO - __main__ -   Time: 2.6686197069993796
03/25/2025 13:26:37 - INFO - __main__ -   Time: 2.71931704599956
03/25/2025 13:26:40 - INFO - __main__ -   Time: 2.8467642340001476
03/25/2025 13:26:42 - INFO - __main__ -   Time: 2.6210546540005453
03/25/2025 13:26:45 - INFO - __main__ -   Time: 2.8377279120013554
03/25/2025 13:26:48 - INFO - __main__ -   Time: 2.6187357879989577
03/25/2025 13:26:50 - INFO - __main__ -   Time: 2.630659196000124
03/25/2025 13:26:53 - INFO - __main__ -   Time: 2.633113460999084
03/25/2025 13:26:56 - INFO - __main__ -   Time: 2.6765003929995146
03/25/2025 13:26:58 - INFO - __main__ -   Time: 2.648193013001219
03/25/2025 13:27:01 - INFO - __main__ -   Time: 2.6311788570001227
03/25/2025 13:27:04 - INFO - __main__ -   Time: 2.704709876999914
03/25/2025 13:27:06 - INFO - __main__ -   Time: 2.6115804759992898
03/25/2025 13:27:09 - INFO - __main__ -   Time: 2.6300997620001
03/25/2025 13:27:12 - INFO - __main__ -   Time: 2.581387549998908
03/25/2025 13:27:14 - INFO - __main__ -   Time: 2.549816130000181
03/25/2025 13:27:14 - INFO - __main__ -   Loading features from cached file /proj/cos568proj2-PG0/glue_data/RTE/cached_dev_bert-base-cased_128_rte
03/25/2025 13:27:14 - INFO - __main__ -   ***** Running evaluation  *****
03/25/2025 13:27:14 - INFO - __main__ -     Num examples = 277
03/25/2025 13:27:14 - INFO - __main__ -     Batch size = 8
03/25/2025 13:27:15 - INFO - __main__ -   loss: 0.6871426701545715
03/25/2025 13:27:15 - INFO - __main__ -   loss: 0.6570183634757996
03/25/2025 13:27:15 - INFO - __main__ -   loss: 0.6268364787101746
03/25/2025 13:27:16 - INFO - __main__ -   loss: 0.6819298267364502
03/25/2025 13:27:16 - INFO - __main__ -   loss: 0.6876116394996643
03/25/2025 13:27:16 - INFO - __main__ -   loss: 0.7114978432655334
03/25/2025 13:27:17 - INFO - __main__ -   loss: 0.6794167160987854
03/25/2025 13:27:17 - INFO - __main__ -   loss: 0.6625320911407471
03/25/2025 13:27:17 - INFO - __main__ -   loss: 0.6569633483886719
03/25/2025 13:27:18 - INFO - __main__ -   loss: 0.7240930199623108
03/25/2025 13:27:18 - INFO - __main__ -   loss: 0.6765318512916565
03/25/2025 13:27:18 - INFO - __main__ -   loss: 0.7123445868492126
03/25/2025 13:27:19 - INFO - __main__ -   loss: 0.6848376393318176
03/25/2025 13:27:19 - INFO - __main__ -   loss: 0.6297593712806702
03/25/2025 13:27:19 - INFO - __main__ -   loss: 0.6256791353225708
03/25/2025 13:27:20 - INFO - __main__ -   loss: 0.7444140911102295
03/25/2025 13:27:20 - INFO - __main__ -   loss: 0.6474671959877014
03/25/2025 13:27:21 - INFO - __main__ -   loss: 0.6614517569541931
03/25/2025 13:27:21 - INFO - __main__ -   loss: 0.6590377688407898
03/25/2025 13:27:21 - INFO - __main__ -   loss: 0.6621359586715698
03/25/2025 13:27:22 - INFO - __main__ -   loss: 0.7446861863136292
03/25/2025 13:27:22 - INFO - __main__ -   loss: 0.6374024748802185
03/25/2025 13:27:22 - INFO - __main__ -   loss: 0.6686539649963379
03/25/2025 13:27:23 - INFO - __main__ -   loss: 0.7021002769470215
03/25/2025 13:27:23 - INFO - __main__ -   loss: 0.6892089247703552
03/25/2025 13:27:23 - INFO - __main__ -   loss: 0.6589744091033936
03/25/2025 13:27:24 - INFO - __main__ -   loss: 0.6862251162528992
03/25/2025 13:27:24 - INFO - __main__ -   loss: 0.7014425992965698
03/25/2025 13:27:24 - INFO - __main__ -   loss: 0.6073501110076904
03/25/2025 13:27:25 - INFO - __main__ -   loss: 0.6942214369773865
03/25/2025 13:27:25 - INFO - __main__ -   loss: 0.6688443422317505
03/25/2025 13:27:25 - INFO - __main__ -   loss: 0.6826649904251099
03/25/2025 13:27:26 - INFO - __main__ -   loss: 0.6384890079498291
03/25/2025 13:27:26 - INFO - __main__ -   loss: 0.666668713092804
03/25/2025 13:27:26 - INFO - __main__ -   loss: 0.6204879879951477
03/25/2025 13:27:26 - INFO - __main__ -   ***** Eval results  *****
03/25/2025 13:27:26 - INFO - __main__ -     acc = 0.5956678700361011
03/25/2025 13:27:26 - INFO - __main__ -   Average time (excluding 1st iteration): 2.804505762473558
03/25/2025 13:27:26 - INFO - __main__ -   All losses: [0.553080677986145, 0.6833480596542358, 0.7658577561378479, 0.7275228500366211, 0.7949894666671753, 0.7498283982276917, 0.6929317712783813, 0.7075834274291992, 0.694621205329895, 0.7708045244216919, 0.642568051815033, 0.7287094593048096, 0.6738929748535156, 0.695283055305481, 0.6508044004440308, 0.694806694984436, 0.6531872153282166, 0.7209987640380859, 0.7320919036865234, 0.730612576007843, 0.7196308374404907, 0.640345573425293, 0.7004303932189941, 0.646530032157898, 0.6956145763397217, 0.6994901895523071, 0.6822206974029541, 0.6823103427886963, 0.6600848436355591, 0.7467132210731506, 0.7060876488685608, 0.7180250883102417, 0.7450602650642395, 0.6618823409080505, 0.6554070115089417, 0.662184476852417, 0.7151358127593994, 0.6515949964523315, 0.6480486989021301]
03/25/2025 13:27:26 - INFO - __main__ -    global_step = 39, average loss = 0.6948800071691855
03/25/2025 13:27:26 - INFO - __main__ -   Loading features from cached file /proj/cos568proj2-PG0/glue_data/RTE/cached_dev_bert-base-cased_128_rte
03/25/2025 13:27:27 - INFO - __main__ -   ***** Running evaluation  *****
03/25/2025 13:27:27 - INFO - __main__ -     Num examples = 277
03/25/2025 13:27:27 - INFO - __main__ -     Batch size = 8
03/25/2025 13:27:27 - INFO - __main__ -   loss: 0.6871426701545715
03/25/2025 13:27:27 - INFO - __main__ -   loss: 0.6570183634757996
03/25/2025 13:27:28 - INFO - __main__ -   loss: 0.6268364787101746
03/25/2025 13:27:28 - INFO - __main__ -   loss: 0.6819298267364502
03/25/2025 13:27:28 - INFO - __main__ -   loss: 0.6876116394996643
03/25/2025 13:27:29 - INFO - __main__ -   loss: 0.7114978432655334
03/25/2025 13:27:29 - INFO - __main__ -   loss: 0.6794167160987854
03/25/2025 13:27:29 - INFO - __main__ -   loss: 0.6625320911407471
03/25/2025 13:27:30 - INFO - __main__ -   loss: 0.6569633483886719
03/25/2025 13:27:30 - INFO - __main__ -   loss: 0.7240930199623108
03/25/2025 13:27:30 - INFO - __main__ -   loss: 0.6765318512916565
03/25/2025 13:27:31 - INFO - __main__ -   loss: 0.7123445868492126
03/25/2025 13:27:31 - INFO - __main__ -   loss: 0.6848376393318176
03/25/2025 13:27:31 - INFO - __main__ -   loss: 0.6297593712806702
03/25/2025 13:27:32 - INFO - __main__ -   loss: 0.6256791353225708
03/25/2025 13:27:32 - INFO - __main__ -   loss: 0.7444140911102295
03/25/2025 13:27:32 - INFO - __main__ -   loss: 0.6474671959877014
03/25/2025 13:27:33 - INFO - __main__ -   loss: 0.6614517569541931
03/25/2025 13:27:33 - INFO - __main__ -   loss: 0.6590377688407898
03/25/2025 13:27:33 - INFO - __main__ -   loss: 0.6621359586715698
03/25/2025 13:27:34 - INFO - __main__ -   loss: 0.7446861863136292
03/25/2025 13:27:34 - INFO - __main__ -   loss: 0.6374024748802185
03/25/2025 13:27:34 - INFO - __main__ -   loss: 0.6686539649963379
03/25/2025 13:27:35 - INFO - __main__ -   loss: 0.7021002769470215
03/25/2025 13:27:35 - INFO - __main__ -   loss: 0.6892089247703552
03/25/2025 13:27:35 - INFO - __main__ -   loss: 0.6589744091033936
03/25/2025 13:27:36 - INFO - __main__ -   loss: 0.6862251162528992
03/25/2025 13:27:36 - INFO - __main__ -   loss: 0.7014425992965698
03/25/2025 13:27:36 - INFO - __main__ -   loss: 0.6073501110076904
03/25/2025 13:27:37 - INFO - __main__ -   loss: 0.6942214369773865
03/25/2025 13:27:37 - INFO - __main__ -   loss: 0.6688443422317505
03/25/2025 13:27:38 - INFO - __main__ -   loss: 0.6826649904251099
03/25/2025 13:27:38 - INFO - __main__ -   loss: 0.6384890079498291
03/25/2025 13:27:38 - INFO - __main__ -   loss: 0.666668713092804
03/25/2025 13:27:38 - INFO - __main__ -   loss: 0.6204879879951477
03/25/2025 13:27:38 - INFO - __main__ -   ***** Eval results  *****
03/25/2025 13:27:38 - INFO - __main__ -     acc = 0.5956678700361011
